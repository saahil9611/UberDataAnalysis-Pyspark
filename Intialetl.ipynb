{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1971fc16",
      "metadata": {
        "id": "1971fc16"
      },
      "source": [
        "# Create a Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d0e80f53",
      "metadata": {
        "id": "d0e80f53",
        "outputId": "a8895286-995c-485f-a5c6-65794b332588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+--------+------+---------------+--------+--------------+\n",
            "|     Date|Time(Local)|Eyeballs|Zeroes|Completed_Trips|Requests|Unique_Drivers|\n",
            "+---------+-----------+--------+------+---------------+--------+--------------+\n",
            "|10-Sep-12|          7|       5|     0|              2|       2|             9|\n",
            "|10-Sep-12|          8|       6|     0|              2|       2|            14|\n",
            "|10-Sep-12|          9|       8|     3|              0|       0|            14|\n",
            "|10-Sep-12|         10|       9|     2|              0|       1|            14|\n",
            "|10-Sep-12|         11|      11|     1|              4|       4|            11|\n",
            "+---------+-----------+--------+------+---------------+--------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.functions import max, min, avg, col, count, date_format\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"UberDataAnalysis\").getOrCreate()\n",
        "\n",
        "# Load the dataset into a DataFrame\n",
        "uber_df = spark.read.csv(\"uber.csv\", header=True, inferSchema=True)\n",
        "uber_df.show(5)  # Display the first 5 rows of the DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e3ee476",
      "metadata": {
        "id": "6e3ee476"
      },
      "source": [
        "# Which date had most completed trips during 3 week period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cb2751f7",
      "metadata": {
        "id": "cb2751f7",
        "outputId": "17357948-1cd3-4b3b-d741-58f347430906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------------------+\n",
            "|     Date|sum(Completed_Trips)|\n",
            "+---------+--------------------+\n",
            "|11-Sep-12|                  40|\n",
            "|13-Sep-12|                  47|\n",
            "|18-Sep-12|                  42|\n",
            "|21-Sep-12|                 190|\n",
            "|12-Sep-12|                  91|\n",
            "|19-Sep-12|                  41|\n",
            "|14-Sep-12|                 305|\n",
            "|16-Sep-12|                 150|\n",
            "|23-Sep-12|                 111|\n",
            "|24-Sep-12|                   4|\n",
            "|22-Sep-12|                 248|\n",
            "|20-Sep-12|                  70|\n",
            "|10-Sep-12|                  26|\n",
            "+---------+--------------------+\n",
            "\n",
            "14-Sep-12\n"
          ]
        }
      ],
      "source": [
        "completed_trips=uber_df.groupBy(\"Date\").sum(\"Completed_Trips\")\n",
        "completed_trips.show()\n",
        "\n",
        "most_completed_trips=completed_trips.orderBy(\"sum(Completed_Trips)\",ascending=False).select(\"Date\").first()[\"Date\"]\n",
        "print(most_completed_trips)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What was the highest number of completed trips within a 24-hour period?"
      ],
      "metadata": {
        "id": "yZjaJzqkVDtw"
      },
      "id": "yZjaJzqkVDtw"
    },
    {
      "source": [
        "#Group the data by 24-hour window\n",
        "from pyspark.sql.functions import to_timestamp, hour, window\n",
        "\n",
        "# Corrected the column name from 'Time (Local)' to 'Time(Local)'\n",
        "uber_df_updated = uber_df.withColumn(\n",
        "    'Time(Local)',\n",
        "    to_timestamp(to_date(col('Date'),'dd-MMM-yy')) + make_interval(hours=hour(col('Time(Local)')))\n",
        ")\n",
        "uber_df_updated.show()\n",
        "# Corrected column name in window function to 'Time(Local)'\n",
        "completed_trips_by_window = uber_df_updated \\\n",
        "    .groupBy(window(\"Time(Local)\", \"24 hours\")) \\\n",
        "    .agg(sum(\"Completed_Trips\").alias(\"Total Completed Trips\")) \\\n",
        "    .orderBy(\"Total Completed Trips\", ascending=False)\n",
        "\n",
        "highest_completed_trips_in_24_hours = completed_trips_by_window \\\n",
        "    .select(\"Total Completed Trips\") \\\n",
        "    .first()[\"Total Completed Trips\"]\n",
        "\n",
        "print(highest_completed_trips_in_24_hours)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWQzdaVn1Trt",
        "outputId": "01243b71-d362-4bf1-b074-8ea32cf9f4e3"
      },
      "id": "oWQzdaVn1Trt",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+--------+------+---------------+--------+--------------+\n",
            "|     Date|        Time(Local)|Eyeballs|Zeroes|Completed_Trips|Requests|Unique_Drivers|\n",
            "+---------+-------------------+--------+------+---------------+--------+--------------+\n",
            "|10-Sep-12|2012-09-10 07:00:00|       5|     0|              2|       2|             9|\n",
            "|10-Sep-12|2012-09-10 08:00:00|       6|     0|              2|       2|            14|\n",
            "|10-Sep-12|2012-09-10 09:00:00|       8|     3|              0|       0|            14|\n",
            "|10-Sep-12|2012-09-10 10:00:00|       9|     2|              0|       1|            14|\n",
            "|10-Sep-12|2012-09-10 11:00:00|      11|     1|              4|       4|            11|\n",
            "|10-Sep-12|2012-09-10 12:00:00|      12|     0|              2|       2|            11|\n",
            "|10-Sep-12|2012-09-10 13:00:00|       9|     1|              0|       0|             9|\n",
            "|10-Sep-12|2012-09-10 14:00:00|      12|     1|              0|       0|             9|\n",
            "|10-Sep-12|2012-09-10 15:00:00|      11|     2|              1|       2|             7|\n",
            "|10-Sep-12|2012-09-10 16:00:00|      11|     2|              3|       4|             6|\n",
            "|10-Sep-12|2012-09-10 17:00:00|      12|     2|              3|       4|             4|\n",
            "|10-Sep-12|2012-09-10 18:00:00|      11|     1|              3|       4|             7|\n",
            "|10-Sep-12|2012-09-10 19:00:00|      13|     2|              2|       3|             7|\n",
            "|10-Sep-12|2012-09-10 20:00:00|      11|     1|              0|       0|             5|\n",
            "|10-Sep-12|2012-09-10 21:00:00|      11|     0|              1|       1|             3|\n",
            "|10-Sep-12|2012-09-10 22:00:00|      16|     3|              0|       2|             4|\n",
            "|10-Sep-12|2012-09-10 23:00:00|      21|     5|              3|       3|             4|\n",
            "|11-Sep-12|2012-09-11 00:00:00|       9|     3|              1|       1|             3|\n",
            "|11-Sep-12|2012-09-11 01:00:00|       3|     2|              0|       1|             3|\n",
            "|11-Sep-12|2012-09-11 02:00:00|       1|     1|              0|       0|             1|\n",
            "+---------+-------------------+--------+------+---------------+--------+--------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Which hour of the day had the most requests during the two-week period?"
      ],
      "metadata": {
        "id": "ZZajLzijg1FD"
      },
      "id": "ZZajLzijg1FD"
    },
    {
      "source": [
        "hourly_requests = uber_df_updated.groupBy(hour(\"Time(Local)\").alias(\"hour\")).agg(sum(\"Requests\").alias(\"total_requests\")).orderBy(\"total_requests\", ascending=False)\n",
        "most_requested_hour = hourly_requests.select(\"hour\").first()[0]\n",
        "print(\"The hour with the most requests is:\", most_requested_hour)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvh506YE2PfN",
        "outputId": "a0a692fb-c813-43bb-9d97-f8077bc8b164"
      },
      "id": "Bvh506YE2PfN",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hour with the most requests is: 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#What percentages of all zeroes during the two-week period occurred on weekends (Friday at 5 pm to Sunday at 3 am)?"
      ],
      "metadata": {
        "id": "U9LHvreQ2Y0Z"
      },
      "id": "U9LHvreQ2Y0Z"
    },
    {
      "source": [
        "from pyspark.sql.functions import col, hour, dayofweek, when, to_date\n",
        "\n",
        "# Cast 'Date' column to date type\n",
        "uber_df_updated = uber_df_updated.withColumn(\"Date\", to_date(col(\"Date\"), \"dd-MMM-yy\"))\n",
        "\n",
        "weekend_zeros = uber_df_updated.filter(\n",
        "    (\n",
        "        (dayofweek(col(\"Date\")) == 6) & (hour(col(\"Time(Local)\")) >= 17)  # Friday 5 pm onwards\n",
        "        | (dayofweek(col(\"Date\")) == 7)  # Saturday all day\n",
        "        | ((dayofweek(col(\"Date\")) == 1) & (hour(col(\"Time(Local)\")) < 3))  # Sunday until 3 am\n",
        "    )\n",
        ").agg(\n",
        "    sum(when(col(\"Zeroes\").isNotNull(), col(\"Zeroes\")).otherwise(0)).alias(\"weekend_zeros\")\n",
        ").collect()[0][\"weekend_zeros\"]\n",
        "\n",
        "total_zeros = uber_df_updated.agg(sum(\"Zeroes\").alias(\"total_zeros\")).collect()[0][\"total_zeros\"]\n",
        "\n",
        "percent_weekend_zeros = (weekend_zeros / total_zeros) * 100 if total_zeros else 0  # Handle division by zero\n",
        "\n",
        "print(\"The percentage of zeros that occurred on weekends is:\", percent_weekend_zeros, \"%\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s4aiBE_4QCd",
        "outputId": "3436a055-5227-44c0-fac3-a265e223f8a9"
      },
      "id": "0s4aiBE_4QCd",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of zeros that occurred on weekends is: 38.20853743876837 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}